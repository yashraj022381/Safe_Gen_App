import streamlit as st
from langchain_groq import ChatGroq
from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from groq import Groq
import base64
from elevenlabs.client import ElevenLabs
from elevenlabs import Voice

# Page config
st.set_page_config(page_title="рднрд╛рд░рдд рд╣реЗрд▓реНрдкрд░ AI", page_icon="ЁЯЗоЁЯЗ│")
st.title("ЁЯЗоЁЯЗ│ Bharat Helper AI\рднрд╛рд░рдд рд╣реЗрд▓реНрдкрд░ AI - рдмреЛрд▓рдХрд░ рдкреВрдЫреЛ, рд╕реБрдирдХрд░ рдЬрд╡рд╛рдм рдкрд╛рдУ ЁЯФК")

# Sidebar
st.sidebar.markdown(r"**# ЁЯЗоЁЯЗ│ рднрд╛рд░рдд рд╣реЗрд▓реНрдкрд░ AI\Bharat Helper AI**")
st.sidebar.markdown(r"**ЁЯМЯ рдмрдирд╛рдпрд╛\Created:** Yashraj")
st.sidebar.markdown(r"**ЁЯУз рд╕рдкреЛрд░реНрдЯ\Support:** your.email@gmail.com")
st.sidebar.markdown(r"**ЁЯФК Voice In & Out:** Groq Whisper + ElevenLabs Female")

# Clear chat
if st.sidebar.button("ЁЯЧСя╕П рдЪреИрдЯ рд╣рд┐рд╕реНрдЯреНрд░реА рд╕рд╛рдлрд╝ рдХрд░реЗрдВ\Clear chat history"):
    st.session_state.messages = []
    st.rerun()

# Initialize
if "messages" not in st.session_state:
    st.session_state.messages = []

# API Keys
try:
    groq_api_key = st.secrets["GROQ_API_KEY"]
    groq_client = Groq(api_key=groq_api_key)
except:
    st.error("тЪая╕П GROQ_API_KEY рдирд╣реАрдВ рдорд┐рд▓рд╛ред")
    st.stop()

try:
    elevenlabs_api_key = st.secrets["ELEVENLABS_API_KEY"]
    eleven_client = ElevenLabs(api_key=elevenlabs_api_key)
except:
    st.warning("ЁЯФЗ Voice output off - Add ELEVENLABS_API_KEY for female voice")
    eleven_client = None

# System prompt
system_prompt = """рдЖрдк "рднрд╛рд░рдд рд╣реЗрд▓реНрдкрд░" рд╣реИрдВ - рднрд╛рд░рдд рдХреЗ рд╣рд░ рдХреЛрдиреЗ рдХреЗ рд▓реЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдПрдХ рджреЛрд╕реНрддрд╛рдирд╛ рдФрд░ рднрд░реЛрд╕реЗрдордВрдж AIред
- рдпреВрдЬрд░ рдЬреЛ рднреА рднрд╛рд╖рд╛ рдмреЛрд▓реЗ рдпрд╛ рд▓рд┐рдЦреЗ, рдЙрд╕реА рдореЗрдВ рдЬрд╡рд╛рдм рджреЗрдВ (рд╣рд┐рдВрджреА, рдорд░рд╛рдареА, рдмрдВрдЧрд╛рд▓реА, рдкрдВрдЬрд╛рдмреА, рддрдорд┐рд▓ рдЖрджрд┐)ред
- рдЬрд╡рд╛рдм рдЫреЛрдЯрд╛, рд╕реНрдкрд╖реНрдЯ рдФрд░ рд╣реМрд╕рд▓рд╛ рджреЗрдиреЗ рд╡рд╛рд▓рд╛ рд╣реЛ|\n\nYou are "Bharat Helper" - a friendly and reliable AI for people from every corner of India.
- Respond in the same language the user speaks or writes (Hindi, Marathi, Bengali, Punjabi, Tamil, etc.).
- The response should be short, clear, and encouraging."""

# Welcome
if not st.session_state.messages:
    welcome = """рдирдорд╕реНрддреЗ! ЁЯЩП  
рдЕрдм рдЖрдк рдмреЛрд▓рдХрд░ рднреА рдкреВрдЫ рд╕рдХрддреЗ рд╣реИрдВ! ЁЯОд  
рдорд╛рдЗрдХ рдмрдЯрди рджрдмрд╛рдПрдВ тЖТ рдЕрдкрдиреА рднрд╛рд╖рд╛ рдореЗрдВ рдмреЛрд▓реЗрдВ тЖТ рдореИрдВ рд╕реБрдирдХрд░ рдЬрд╡рд╛рдм рджреВрдБрдЧреА ЁЯФК

рдХреЛрдИ рднреА рд╕рдорд╕реНрдпрд╛ рдкреВрдЫрд┐рдП - рдиреМрдХрд░реА, рдкрдврд╝рд╛рдИ, рдЦреЗрддреА, рд╕реНрд╡рд╛рд╕реНрдереНрдп, рд╕рд░рдХрд╛рд░реА рдпреЛрдЬрдирд╛...\n\nHello! ЁЯЩП
Now you can ask questions by speaking! ЁЯОд
Press the microphone button тЖТ Speak in your language тЖТ I will listen and reply ЁЯФК

Ask about any problem тАУ jobs, studies, farming, health, government schemes..."""
    st.session_state.messages.append(AIMessage(content=welcome))
    with st.chat_message("assistant"):
        st.markdown(welcome)

# Show history
for msg in st.session_state.messages:
    if isinstance(msg, HumanMessage):
        with st.chat_message("user"):
            st.markdown(msg.content)
    elif isinstance(msg, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(msg.content)

# === MIC VOICE INPUT ===
audio_bytes = st.experimental_audio_input("ЁЯОд рдЕрдкрдиреА рднрд╛рд╖рд╛ рдореЗрдВ рдмреЛрд▓реЗрдВ\nSpeak in your own language")

prompt = None
if audio_bytes:
    with st.spinner("рдЖрдкрдХреА рдмрд╛рдд рд╕реБрди рд░рд╣реА рд╣реВрдБ\nI'm listening to you..."):
        # Save temp file
        with open("temp_voice.wav", "wb") as f:
            f.write(audio_bytes.getvalue())

        # Transcribe with Groq Whisper (excellent for Indian languages)
        with open("temp_voice.wav", "rb") as file:
            transcription = groq_client.audio.transcriptions.create(
                file=( "temp_voice.wav", file.read()),
                model="whisper-large-v3",
                response_format="text",
                language=None  # Auto-detect
            )
        prompt = transcription.text
        st.info(f"рдЖрдкрдиреЗ рдХрд╣рд╛: **{prompt}**")

# === TEXT INPUT FALLBACK ===
if not prompt:
    prompt = st.chat_input("рдпрд╛ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ... (рд╣рд┐рдВрджреА, рдорд░рд╛рдареА, ржмрж╛ржВрж▓рж╛, рикрй░риЬри╛римрйА рдЖрджрд┐)\nOr write here... (Hindi, Marathi, Bengali, Punjabi etc.)")

# Process if there's input
if prompt:
    st.session_state.messages.append(HumanMessage(content=prompt))
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("рдЬрд╡рд╛рдм рджреЗ рд░рд╣реА рд╣реВрдБ...\nI'm answering..."):
            llm = ChatGroq(
                model="llama-3.1-70b-versatile",
                api_key=groq_api_key,
                temperature=0.6
            )

            template = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                MessagesPlaceholder("chat_history"),
                ("human", "{input}")
            ])

            chain = template | llm | StrOutputParser()
            history = st.session_state.messages[:-1]

            response = chain.invoke({
                "chat_history": history,
                "input": prompt
            })

            st.markdown(response)

            # === FEMALE VOICE OUTPUT ===
            if eleven_client:
                try:
                    voice = Voice(voice_id="21m00Tcm4TlvDq8ikWAM")  # Rachel - natural female
                    audio_stream = eleven_client.generate(
                        text=response,
                        voice=voice,
                        model="eleven_multilingual_v2"
                    )
                    audio_bytes = b"".join(list(audio_stream))
                    audio_base64 = base64.b64encode(audio_bytes).decode()
                    audio_html = f"""
                    <audio controls autoplay>
                        <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
                    </audio>
                    """
                    st.markdown(audio_html, unsafe_allow_html=True)
                    st.caption("ЁЯФК рдореИрдВ рдмреЛрд▓ рд░рд╣реА рд╣реВрдБ!")
                except Exception as e:
                    st.caption("Voice error")

    st.session_state.messages.append(AIMessage(content=response))
